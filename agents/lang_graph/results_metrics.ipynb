{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_content(text):\n",
    "    # Use a regular expression to find content between [[ and ]]\n",
    "    match = re.search(r'\\[\\[(.*?)\\]\\]', text)\n",
    "    if match:\n",
    "        # Return the content as a string\n",
    "        return match.group(1).lower()\n",
    "    else:\n",
    "        # Return None if no match is found\n",
    "        return None\n",
    "    \n",
    "def extract_number(text):\n",
    "    # Use a regular expression to find a number between [[ and ]]\n",
    "    match = re.findall(r'\\[\\[(\\d+)\\]\\]', text)\n",
    "    if match:\n",
    "        # Return the number as an integer\n",
    "        return int(match[-1])\n",
    "    else:\n",
    "        # Return None if no match is found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cat_ls = []\n",
    "metrics_entity_look_ls = []\n",
    "metrics_landmark_look_ls = []\n",
    "metrics_ans_form_ls = []\n",
    "\n",
    "for eval_type in ['openai', 'full_hf_140', 'no_entity', 'no_reference']:\n",
    "    # read the questions\n",
    "    results = pd.read_csv('data/questions_140.csv')[['id', 'question', 'category', 'answer_format', 'n_matches', 'entity_match']]\n",
    "\n",
    "    # select questions that requires entity/landmark look up\n",
    "    results['requires_landmark_look_up'] = False\n",
    "    results.loc[(results['n_matches'] > 0) & (results['entity_match'] == 0), 'requires_landmark_look_up'] = True\n",
    "    results['requires_entity_look_up'] = results['entity_match'] == 1\n",
    "\n",
    "    # read the outputs\n",
    "    if eval_type=='openai':\n",
    "        seed1, seed2, seed3 = (1131, 2352, 3158)\n",
    "    if eval_type=='full_hf_140':\n",
    "        seed1, seed2, seed3 = (1095, 2109, 2455)\n",
    "    if eval_type=='no_entity':\n",
    "        seed1, seed2, seed3 = (1048, 7463, 2705)\n",
    "    if eval_type=='no_reference':\n",
    "        seed1, seed2, seed3 = (2559, 3032, 2798)\n",
    "\n",
    "    i1 = pd.read_csv(f'out_{eval_type}/out_info_{seed1}.csv')\n",
    "    i2 = pd.read_csv(f'out_{eval_type}/out_info_{seed2}.csv')\n",
    "    i3 = pd.read_csv(f'out_{eval_type}/out_info_{seed3}.csv')\n",
    "\n",
    "    i1 = i1[i1['output'].notna()]\n",
    "    i2 = i2[i2['output'].notna()]\n",
    "    i3 = i3[i3['output'].notna()]\n",
    "\n",
    "    i1 = i1[i1['info_output'].notna()]\n",
    "    i2 = i2[i2['info_output'].notna()]\n",
    "    i3 = i3[i3['info_output'].notna()]\n",
    "\n",
    "    # output extraction\n",
    "    i1['code_out_1'] = i1['output'].apply(extract_content)\n",
    "    i1.loc[(i1['code_out_1']=='nan') & (i1['answer_format']=='yes or no'), 'code_out_1'] = 'no'\n",
    "    i1.loc[(i1['code_out_1']=='nan') & (i1['answer_format']=='a single number'), 'code_out_1'] = '0'\n",
    "    i1.drop(i1[(i1['code_out_1'] == 'nan') & (i1['answer_format'] == 'a single entity name')].index, inplace=True)\n",
    "\n",
    "    i2['code_out_2'] = i2['output'].apply(extract_content)\n",
    "    i2.loc[(i2['code_out_2']=='nan') & (i2['answer_format']=='yes or no'), 'code_out_2'] = 'no'\n",
    "    i2.loc[(i2['code_out_2']=='nan') & (i2['answer_format']=='a single number'), 'code_out_2'] = '0'\n",
    "    i2.drop(i2[(i2['code_out_2'] == 'nan') & (i2['answer_format'] == 'a single entity name')].index, inplace=True)\n",
    "\n",
    "    i3['code_out_3'] = i3['output'].apply(extract_content)\n",
    "    i3.loc[(i3['code_out_3']=='nan') & (i3['answer_format']=='yes or no'), 'code_out_3'] = 'no'\n",
    "    i3.loc[(i3['code_out_3']=='nan') & (i3['answer_format']=='a single number'), 'code_out_3'] = '0'\n",
    "    i3.drop(i3[(i3['code_out_3'] == 'nan') & (i3['answer_format'] == 'a single entity name')].index, inplace=True)\n",
    "\n",
    "    i1['info_out_1'] = i1['info_output'].apply(extract_number)\n",
    "    i2['info_out_2'] = i2['info_output'].apply(extract_number)\n",
    "    i3['info_out_3'] = i3['info_output'].apply(extract_number)\n",
    "\n",
    "    results = pd.merge(results, i1[['id', 'code_out_1', 'info_out_1']], on='id', how='left')\n",
    "    results = pd.merge(results, i2[['id', 'code_out_2', 'info_out_2']], on='id', how='left')\n",
    "    results = pd.merge(results, i3[['id', 'code_out_3', 'info_out_3']], on='id', how='left')\n",
    "\n",
    "    # success rate\n",
    "    results['success_1'] = 0\n",
    "    results.loc[results['code_out_1'].notna() | results['code_out_2'].notna() | results['code_out_3'].notna(), 'success_1'] = 1\n",
    "\n",
    "    results['success_3'] = 0\n",
    "    results.loc[results['code_out_1'].notna() & results['code_out_2'].notna() & results['code_out_3'].notna(), 'success_3'] = 1\n",
    "\n",
    "    # consistency score\n",
    "    results['consistency_2'] = 0\n",
    "    results.loc[(results['success_1'] == 1) & ((results['code_out_1'] == results['code_out_2']) | (results['code_out_1'] == results['code_out_3']) | (results['code_out_3'] == results['code_out_2'])), 'consistency_2'] = 1\n",
    "\n",
    "    results['consistency_3'] = 0\n",
    "    results.loc[(results['success_3'] == 1) & (results['code_out_1'] == results['code_out_2']) & (results['code_out_1'] == results['code_out_3']), 'consistency_3'] = 1\n",
    "\n",
    "    # information gain\n",
    "    results['info_gain_2_2'] = 0\n",
    "    results.loc[(results['consistency_2'] == 1) & (((results['info_out_1'] == results['info_out_2']) & ((results['code_out_1'] == results['code_out_2']))) | \n",
    "                                                ((results['info_out_2'] == results['info_out_3']) & ((results['code_out_2'] == results['code_out_3']))) | \n",
    "                                                ((results['info_out_1'] == results['info_out_3']) & ((results['code_out_1'] == results['code_out_3'])))), 'info_gain_2_2'] = 1\n",
    "\n",
    "    results['info_gain_3_2'] = 0\n",
    "    results.loc[(results['consistency_3'] == 1) & ((results['info_out_1'] == results['info_out_2']) | (results['info_out_2'] == results['info_out_3']) | (results['info_out_1'] == results['info_out_3'])), 'info_gain_3_2'] = 1\n",
    "\n",
    "    results['info_gain_3_3'] = 0\n",
    "    results.loc[(results['consistency_3'] == 1) & (results['info_out_1'] == results['info_out_2']) & (results['info_out_2'] == results['info_out_3']), 'info_gain_3_3'] = 1\n",
    "    \n",
    "    # information gain = 0\n",
    "    # results['info_gain_3_2_zero'] = 0\n",
    "    # results.loc[(results['info_gain_3_2'] == 1) & (((results['info_out_1']==0) & (results['info_out_2']==0)) | ((results['info_out_1']==0) & (results['info_out_3']==0)) | ((results['info_out_3']==0) & (results['info_out_2']==0))), 'info_gain_3_2_zero'] = 1\n",
    "\n",
    "    results['info_gain_3_3_zero'] = 0\n",
    "    results.loc[(results['info_gain_3_3'] == 1) & (results['info_out_1']==0), 'info_gain_3_3_zero'] = 1\n",
    "\n",
    "    # compute all metrics\n",
    "    metrics = ['success_1', 'success_3', 'consistency_2', 'consistency_3', 'info_gain_3_3', 'info_gain_3_2', 'info_gain_2_2', 'info_gain_3_3_zero']\n",
    "    metrics_rename = {\n",
    "        'success_1': \"Success Rate (at least 1 seed)\", \n",
    "        'success_3': \"Success Rate (all 3 seeds)\",\n",
    "        'consistency_2': \"Consistency (at least 2 seeds)\", \n",
    "        'consistency_3': \"Consistency (all 3 seeds)\", \n",
    "        'info_gain_3_3': \"Info Gain (Consistency 3 + Info Gain 3)\", \n",
    "        'info_gain_3_2': \"Info Gain (Consistency 3 + Info Gain 2)\", \n",
    "        'info_gain_2_2': \"Info Gain (Consistency 2 + Info Gain 2)\",\n",
    "        'info_gain_3_3_zero': \"Info Gain (Consistency 3 + Info Gain 3) => 0\",\n",
    "        # 'info_gain_3_2_zero': \"Info Gain (Consistency 3 + Info Gain 2) => 0\",\n",
    "        # 'info_gain_2_2_zero': \"Info Gain (Consistency 2 + Info Gain 2) => 0\",\n",
    "    }\n",
    "\n",
    "    # compute average metrics\n",
    "    metrics_cat = results.groupby('category', as_index=False)[metrics].mean().rename(metrics_rename, axis=1)\n",
    "    metrics_cat['eval_type'] = eval_type\n",
    "    metrics_cat_ls.append(metrics_cat)\n",
    "    \n",
    "    metrics_entity_look = results.groupby('requires_entity_look_up', as_index=False)[metrics].mean().rename(metrics_rename, axis=1)\n",
    "    metrics_entity_look['eval_type'] = eval_type\n",
    "    metrics_entity_look_ls.append(metrics_entity_look)\n",
    "\n",
    "    metrics_landmark_look = results.groupby('requires_landmark_look_up', as_index=False)[metrics].mean().rename(metrics_rename, axis=1)\n",
    "    metrics_landmark_look['eval_type'] = eval_type\n",
    "    metrics_landmark_look_ls.append(metrics_landmark_look)\n",
    "\n",
    "    metrics_ans_form = results.groupby('answer_format', as_index=False)[metrics].mean().rename(metrics_rename, axis=1)\n",
    "    metrics_ans_form['eval_type'] = eval_type\n",
    "    metrics_ans_form_ls.append(metrics_ans_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(metrics_rename.values())\n",
    "\n",
    "metrics_cat_all = pd.concat(metrics_cat_ls)\n",
    "metrics_cat_all.groupby(['category', 'eval_type'])[metrics].first().to_excel('metrics_cat.xlsx')\n",
    "\n",
    "metrics_entity_look_all = pd.concat(metrics_entity_look_ls)\n",
    "metrics_entity_look_all.groupby(['requires_entity_look_up', 'eval_type'])[metrics].first().to_excel('metrics_entity_lookup.xlsx')\n",
    "\n",
    "metrics_landmark_look_all = pd.concat(metrics_landmark_look_ls)\n",
    "metrics_landmark_look_all.groupby(['requires_landmark_look_up', 'eval_type'])[metrics].first().to_excel('metrics_landmark_lookup.xlsx')\n",
    "\n",
    "metrics_ans_form_all = pd.concat(metrics_ans_form_ls)\n",
    "metrics_ans_form_all.groupby(['answer_format', 'eval_type'])[metrics].first().to_excel('metrics_ans_format.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requires_entity_look_up</th>\n",
       "      <th>Success Rate (at least 1 seed)</th>\n",
       "      <th>Success Rate (all 3 seeds)</th>\n",
       "      <th>Consistency (at least 2 seeds)</th>\n",
       "      <th>Consistency (all 3 seeds)</th>\n",
       "      <th>Info Gain (Consistency 3 + Info Gain 3)</th>\n",
       "      <th>Info Gain (Consistency 3 + Info Gain 2)</th>\n",
       "      <th>Info Gain (Consistency 2 + Info Gain 2)</th>\n",
       "      <th>Info Gain (Consistency 3 + Info Gain 3) =&gt; 0</th>\n",
       "      <th>eval_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.329268</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>full_hf_140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>full_hf_140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no_entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>no_entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no_reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>no_reference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   requires_entity_look_up  Success Rate (at least 1 seed)   \n",
       "0                    False                        1.000000  \\\n",
       "1                     True                        1.000000   \n",
       "0                    False                        0.987805   \n",
       "1                     True                        1.000000   \n",
       "0                    False                        0.914634   \n",
       "1                     True                        0.844828   \n",
       "0                    False                        0.975610   \n",
       "1                     True                        1.000000   \n",
       "\n",
       "   Success Rate (all 3 seeds)  Consistency (at least 2 seeds)   \n",
       "0                    0.975610                        0.878049  \\\n",
       "1                    0.931034                        0.862069   \n",
       "0                    0.560976                        0.524390   \n",
       "1                    0.655172                        0.586207   \n",
       "0                    0.365854                        0.414634   \n",
       "1                    0.431034                        0.500000   \n",
       "0                    0.292683                        0.365854   \n",
       "1                    0.344828                        0.586207   \n",
       "\n",
       "   Consistency (all 3 seeds)  Info Gain (Consistency 3 + Info Gain 3)   \n",
       "0                   0.536585                                 0.329268  \\\n",
       "1                   0.551724                                 0.379310   \n",
       "0                   0.170732                                 0.097561   \n",
       "1                   0.258621                                 0.137931   \n",
       "0                   0.085366                                 0.024390   \n",
       "1                   0.293103                                 0.172414   \n",
       "0                   0.073171                                 0.012195   \n",
       "1                   0.206897                                 0.172414   \n",
       "\n",
       "   Info Gain (Consistency 3 + Info Gain 2)   \n",
       "0                                 0.512195  \\\n",
       "1                                 0.551724   \n",
       "0                                 0.121951   \n",
       "1                                 0.224138   \n",
       "0                                 0.073171   \n",
       "1                                 0.275862   \n",
       "0                                 0.060976   \n",
       "1                                 0.206897   \n",
       "\n",
       "   Info Gain (Consistency 2 + Info Gain 2)   \n",
       "0                                 0.731707  \\\n",
       "1                                 0.844828   \n",
       "0                                 0.243902   \n",
       "1                                 0.379310   \n",
       "0                                 0.268293   \n",
       "1                                 0.448276   \n",
       "0                                 0.219512   \n",
       "1                                 0.327586   \n",
       "\n",
       "   Info Gain (Consistency 3 + Info Gain 3) => 0     eval_type  \n",
       "0                                      0.000000        openai  \n",
       "1                                      0.068966        openai  \n",
       "0                                      0.012195   full_hf_140  \n",
       "1                                      0.051724   full_hf_140  \n",
       "0                                      0.000000     no_entity  \n",
       "1                                      0.172414     no_entity  \n",
       "0                                      0.000000  no_reference  \n",
       "1                                      0.086207  no_reference  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_entity_look_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
